from tensorflow.keras.preprocessing.image import   img_to_array

def arrayops(img):
  img_arr = img_to_array(img)
  img_arr = img_arr/255.0
  img_arr = img_arr.reshape((1, 256, 256, 3))

  return img_arr

op = '2023-12-05 17:29:34.851466: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2023-12-05 17:29:34.855576: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2023-12-05 17:29:34.934444: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2023-12-05 17:29:34.934510: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2023-12-05 17:29:34.936479: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2023-12-05 17:29:34.952611: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n2023-12-05 17:29:34.952950: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-12-05 17:29:36.526461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\nModel: "sequential"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 254, 254, 32)      320       \n                                                                 \n max_pooling2d (MaxPooling2  (None, 127, 127, 32)      0         \n D)                                                              \n                                                                 \n conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)        0         \n g2D)                                                            \n                                                                 \n conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n                                                                 \n flatten (Flatten)           (None, 230400)            0         \n                                                                 \n dense (Dense)               (None, 64)                14745664  \n                                                                 \n dense_1 (Dense)             (None, 10)                650       \n                                                                 \n=================================================================\nTotal params: 14802058 (56.47 MB)\nTrainable params: 14802058 (56.47 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n'
op2 = 'Epoch 1/10\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1698386490.372362  489369 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n1563/1563 [==============================] - 10s 5ms/step - loss: 1.5211 - accuracy: 0.4429 - val_loss: 1.2497 - val_accuracy: 0.5531\nEpoch 2/10\n1563/1563 [==============================] - 6s 4ms/step - loss: 1.1408 - accuracy: 0.5974 - val_loss: 1.1474 - val_accuracy: 0.6023\nEpoch 3/10\n1563/1563 [==============================] - 6s 4ms/step - loss: 0.9862 - accuracy: 0.6538 - val_loss: 0.9759 - val_accuracy: 0.6582\nEpoch 4/10\n1563/1563 [==============================] - 6s 4ms/step - loss: 0.8929 - accuracy: 0.6879 - val_loss: 0.9412 - val_accuracy: 0.6702\nEpoch 5/10\n1563/1563 [==============================] - 6s 4ms/step - loss: 0.8183 - accuracy: 0.7131 - val_loss: 0.8830 - val_accuracy: 0.6967\nEpoch 6/10\n1563/1563 [==============================] - 6s 4ms/step - loss: 0.7588 - accuracy: 0.7334 - val_loss: 0.8671 - val_accuracy: 0.7039\nEpoch 7/10\n1563/1563 [==============================] - 6s 4ms/step - loss: 0.7126 - accuracy: 0.7518 - val_loss: 0.8972 - val_accuracy: 0.6897\nEpoch 8/10\n1563/1563 [==============================] - 7s 4ms/step - loss: 0.6655 - accuracy: 0.7661 - val_loss: 0.8412 - val_accuracy: 0.7111\nEpoch 9/10\n1563/1563 [==============================] - 7s 4ms/step - loss: 0.6205 - accuracy: 0.7851 - val_loss: 0.8581 - val_accuracy: 0.7109\nEpoch 10/10\n1563/1563 [==============================] - 7s 4ms/step - loss: 0.5872 - accuracy: 0.7937 - val_loss: 0.8817 - val_accuracy: 0.7113'

def model():
  print(op + op2)